{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreas/.conda/envs/tf36/lib/python3.6/site-packages/packaging/requirements.py:66: UserWarning: warn_ungrouped_named_tokens_in_collection: setting results name 'specifier' on And expression collides with '_original_end' on contained expression\n",
      "  VERSION_SPEC = originalTextFor(_VERSION_SPEC)(\"specifier\")\n",
      "/home/andreas/.conda/envs/tf36/lib/python3.6/site-packages/packaging/requirements.py:69: UserWarning: warn_ungrouped_named_tokens_in_collection: setting results name 'marker' on And expression collides with '_original_end' on contained expression\n",
      "  MARKER_EXPR = originalTextFor(MARKER_EXPR())(\"marker\")\n"
     ]
    }
   ],
   "source": [
    "from poetry_generator import start_poetry_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jambus = [0,1]\n",
    "trochee = [1,0]\n",
    "\n",
    "prompt = '''Die Philosophie ist ein schlechtes Metier.\n",
    "Wahrhaftig, ich begreife nie,\n",
    "Warum man treibt Philosophie.\n",
    "Sie ist langweilig und bringt nichts ein,\n",
    "Und gottlos ist sie obendrein;'''\n",
    "\n",
    "num_syll_list =[9,11]                               # number of syllables of one Verse; if it is a list\n",
    "                                                    # the lenght of the verses will iterate accordingly\n",
    "                                                                    \n",
    "rhyme_scheme = 'abab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -1.0, 0.0, 1.0]\n",
      "start generating\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result by: GPT2-large\n",
      "rhyme scheme: abab\n",
      "rating: 11.431368270382839\n",
      "\n",
      "Das macht sogar die frommen Pfaffen \n",
      "\n",
      "start generating\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result by: GPT2-large\n",
      "rhyme scheme: abab\n",
      "rating: 6.518119917851161\n",
      "\n",
      "Das macht sogar die frommen Pfaffen \n",
      "Denn in Denn in das , wie ich meine , steckt ein \n",
      "\n",
      "start generating\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- looking for rhymes ---\n",
      "using GPT2-large\n",
      "Das macht sogar die frommen Pfaffen\n",
      "Daß Menschen , die nicht irren können ,\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of found alternatives\n",
      "causal:\n",
      "3\n",
      "bidirectional:\n",
      "55\n",
      "-----------------------------\n",
      "matching vowels\n",
      "final choice:\n",
      "römer\n",
      "Daß Menschen , die nicht irren können ,\n",
      "result by: GPT2-large\n",
      "rhyme scheme: abab\n",
      "rating: 5.557054523679466\n",
      "\n",
      "Das macht sogar die frommen römer\n",
      "Denn in Denn in das , wie ich meine , steckt ein\n",
      "Daß Menschen , die nicht irren können ,\n",
      "\n",
      "start generating\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- looking for rhymes ---\n",
      "using GPT2-large\n",
      "Denn in Denn in das , wie ich meine , steckt ein\n",
      "Nach allem , was sie tun , sie selbst nicht fragen ,\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of found alternatives\n",
      "causal:\n",
      "14\n",
      "bidirectional:\n",
      "1\n",
      "-----------------------------\n",
      "rhyme not found\n",
      "final choice:\n",
      "ein\n",
      "Nach allem , was sie tun , sie selbst nicht fragen ,\n",
      "result by: GPT2-large\n",
      "rhyme scheme: abab\n",
      "rating: 10.206002053004838\n",
      "\n",
      "Das macht sogar die frommen römer\n",
      "Denn in Denn in das , wie ich meine , steckt ein\n",
      "Daß Menschen , die nicht irren können ,\n",
      "Nach allem , was sie tun , sie selbst nicht fragen ,\n",
      "\n",
      "start generating\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result by: GPT2-large\n",
      "rhyme scheme: abab\n",
      "rating: 14.601901772042469\n",
      "\n",
      "Das macht sogar die frommen römer\n",
      "Denn in Denn in das , wie ich meine , steckt ein\n",
      "Daß Menschen , die nicht irren können ,\n",
      "Nach allem , was sie tun , sie selbst nicht fragen ,\n",
      "Sie selber auch nicht irren können , \n",
      "\n",
      "start generating\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result by: GPT2-large\n",
      "rhyme scheme: abab\n",
      "rating: 14.594042510359698\n",
      "\n",
      "Das macht sogar die frommen römer\n",
      "Denn in Denn in das , wie ich meine , steckt ein\n",
      "Daß Menschen , die nicht irren können ,\n",
      "Nach allem , was sie tun , sie selbst nicht fragen ,\n",
      "Sie selber auch nicht irren können , \n",
      "Daß diese Menschen also schlecht und sinnlos , \n",
      "\n",
      "start generating\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter extension\n",
      "[MASK] weil sie nicht irren können\n",
      "weil [MASK] sie nicht irren können \n",
      "weil sie [MASK] nicht irren können \n",
      "weil sie nicht [MASK] irren können \n",
      "weil sie nicht irren [MASK] können \n",
      "rythm:\n",
      "[[0.0, 1.0], [0.5], [0.5], [0], [1.0, 0.0], [1.0, 0.0]]\n",
      "--- looking for rhymes ---\n",
      "using GPT2-large\n",
      "Sie selber auch nicht irren können ,\n",
      "warum weil sie nicht irren können\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of found alternatives\n",
      "causal:\n",
      "165\n",
      "bidirectional:\n",
      "36\n",
      "-----------------------------\n",
      "found via colone phonetics\n",
      "final choice:\n",
      "kennen\n",
      "warum weil sie nicht irren können\n",
      "result by: GPT2-large\n",
      "rhyme scheme: abab\n",
      "rating: 13.006803088321861\n",
      "\n",
      "Das macht sogar die frommen römer\n",
      "Denn in Denn in das , wie ich meine , steckt ein\n",
      "Daß Menschen , die nicht irren können ,\n",
      "Nach allem , was sie tun , sie selbst nicht fragen ,\n",
      "Sie selber auch nicht irren kennen\n",
      "Daß diese Menschen also schlecht und sinnlos ,\n",
      "warum weil sie nicht irren können\n",
      "\n",
      "start generating\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- looking for rhymes ---\n",
      "using GPT2-large\n",
      "Daß diese Menschen also schlecht und sinnlos ,\n",
      "Die Leute ohne daß sie fragen können ?\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of found alternatives\n",
      "causal:\n",
      "45\n",
      "bidirectional:\n",
      "26\n",
      "-----------------------------\n",
      "matching vowels\n",
      "final choice:\n",
      "alle\n",
      "Die Leute ohne daß  ich ihnen sage,\n",
      "result by: GPT2-large\n",
      "rhyme scheme: abab\n",
      "rating: 14.334321092642025\n",
      "\n",
      "Das macht sogar die frommen römer\n",
      "Denn in Denn in das , wie ich meine , steckt ein\n",
      "Daß Menschen , die nicht irren können ,\n",
      "Nach allem , was sie tun , sie selbst nicht fragen ,\n",
      "Sie selber auch nicht irren kennen\n",
      "Daß diese Menschen also schlecht und alle\n",
      "warum weil sie nicht irren können\n",
      "Die Leute ohne daß ich ihnen sage ,\n",
      "\n",
      "start generating\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result by: GPT2-large\n",
      "rhyme scheme: abab\n",
      "rating: 18.494096674803128\n",
      "\n",
      "Das macht sogar die frommen römer\n",
      "Denn in Denn in das , wie ich meine , steckt ein\n",
      "Daß Menschen , die nicht irren können ,\n",
      "Nach allem , was sie tun , sie selbst nicht fragen ,\n",
      "Sie selber auch nicht irren kennen\n",
      "Daß diese Menschen also schlecht und alle\n",
      "warum weil sie nicht irren können\n",
      "Die Leute ohne daß ich ihnen sage ,\n",
      "Daß sie die Welt nicht falsch verstehen \n",
      "\n",
      "start generating\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result by: GPT2-large\n",
      "rhyme scheme: abab\n",
      "rating: 23.154498315817275\n",
      "\n",
      "Das macht sogar die frommen römer\n",
      "Denn in Denn in das , wie ich meine , steckt ein\n",
      "Daß Menschen , die nicht irren können ,\n",
      "Nach allem , was sie tun , sie selbst nicht fragen ,\n",
      "Sie selber auch nicht irren kennen\n",
      "Daß diese Menschen also schlecht und alle\n",
      "warum weil sie nicht irren können\n",
      "Die Leute ohne daß ich ihnen sage ,\n",
      "Daß sie die Welt nicht falsch verstehen \n",
      "Der Mensch ist dumm und macht die Welt zu eitel , \n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/poem_1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2cd3b3044d10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mLLM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GPT2-large'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0mLLM_rhyme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GPT2-large'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                         use_tts = False)\n\u001b[0m",
      "\u001b[0;32m~/LLM_poetry_generation/poetry_generator.py\u001b[0m in \u001b[0;36mstart_poetry_generation\u001b[0;34m(prompt, target_rythm, num_syll_lst, rhyme_scheme, shots, loops, LLM, LLM_rhyme, use_tts)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_poetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_rythm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_syll_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhyme_scheme\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLLM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/poem_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/poem_1.txt'"
     ]
    }
   ],
   "source": [
    "start_poetry_generation(prompt,\n",
    "                        jambus,\n",
    "                        num_syll_list,\n",
    "                        rhyme_scheme,\n",
    "                        shots = 1,\n",
    "                        loops = 1,\n",
    "                        LLM='GPT2-large',\n",
    "                        LLM_rhyme='GPT2-large',\n",
    "                        use_tts = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
