{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andjoer/llm_poetry_generation/blob/main/colabs/llm_theo_lutz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrZ2myE2M3NO"
      },
      "source": [
        "# Inspired by Theo Lutz\n",
        "\n",
        "## Combining large language models and patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "click the 'Run all' button\n",
        "\n",
        "<img src = 'https://github.com/andjoer/llm_poetry_generation/blob/main/graphics/colab_en.jpg?raw=true'>\n",
        "\n",
        "German\n",
        "\n",
        "\n",
        "\n",
        "<img src = 'https://github.com/andjoer/llm_poetry_generation/blob/main/graphics/colab.jpg?raw=true'>"
      ],
      "metadata": {
        "id": "91QWM1NGy9OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "9wXHQY89M4Z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df37a739-e360-4d85-9af9-bef7a4ea6162"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 68.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 14.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dkFCIitvM3NQ"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer,GPT2LMHeadModel, pipeline\n",
        "import numpy as np\n",
        "import torch\n",
        "import spacy\n",
        "import functools\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download \"de_core_news_lg\"\n",
        "\n",
        "nlp = spacy.load(\"de_core_news_lg\")"
      ],
      "metadata": {
        "id": "ElLwUBMRNOAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db96f604-e203-4a0c-f97c-27154cfb0581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-lg==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_lg-3.3.0/de_core_news_lg-3.3.0-py3-none-any.whl (567.8 MB)\n",
            "\u001b[K     |████                            | 72.7 MB 492 kB/s eta 0:16:47"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3rENvHMM3NT"
      },
      "source": [
        "## Defining the model to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsVgvkYIM3NU"
      },
      "outputs": [],
      "source": [
        "gpt2_model = \"Anjoe/kant-gpt2-large\"\n",
        "\n",
        "generator = pipeline('text-generation', model=gpt2_model,\n",
        "                 tokenizer=gpt2_model, framework = 'pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GEKYuevM3NW"
      },
      "outputs": [],
      "source": [
        "def gpt2_generate(input_text,max_length= 5, num_return_sequences=30):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(gpt2_model)\n",
        "    max_length += tokenizer.encode(input_text,return_tensors='pt').size(1)\n",
        "    generated = generator(input_text, max_length=max_length,return_full_text = False, num_return_sequences=num_return_sequences)\n",
        "    \n",
        "    return [item['generated_text'] for item in generated]\n",
        "\n",
        "\n",
        "def gpt2_top_k(input_text,max_length = 10,num_return_sequences=30):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(gpt2_model)\n",
        "    model = GPT2LMHeadModel.from_pretrained(gpt2_model,pad_token_id = tokenizer.eos_token_id)\n",
        "    input_ids = tokenizer.encode(input_text,return_tensors='pt')\n",
        "    max_length += input_ids.size(1)\n",
        "    start = input_ids.size()[1]\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        do_sample = True,\n",
        "        max_length = max_length,\n",
        "        top_k = num_return_sequences,\n",
        "        num_return_sequences = num_return_sequences,\n",
        "        early_stopping = True,\n",
        "        num_repeat_ngram_size = 2\n",
        "    )\n",
        "\n",
        "    return [tokenizer.decode(sample_output[start:],skip_special_tokens=True) for sample_output in output]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4JZco4bM3NX"
      },
      "source": [
        "## Define the patterns\n",
        "\n",
        "A sequence of \"nodes\" is defined."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patterns_lutz_org = []\n",
        "\n",
        "\n",
        "#######################################################\n",
        "#0\n",
        "patterns_lutz_org.append({'type':'generate',                 # use the language model to produce text\n",
        "                 'any': True,                         # word can be found anywhere in the text\n",
        "                 'num_samples':20,                    # number of samples that comply with the criteria\n",
        "                 'pos':[['NOUN']],     # should be either sequence adjective, noun or only noun\n",
        "                 'number': [['Sing']],\n",
        "                 'case':[['Nom']],         # the Noun should be nominative\n",
        "                 'next':1})                           # next node\n",
        "\n",
        "            \n",
        "#######################################################\n",
        "#1\n",
        "patterns_lutz_org.append({'type':'insertion',\n",
        "                 'dependent':['gender'],\n",
        "                 'dependency': -1,\n",
        "                 'position': 'before',                      # only possible with insertion\n",
        "                 'Fem':['eine','jede','keine','nicht jede'],  \n",
        "                 'Masc':['ein','jeder','kein','nicht jeder'],\n",
        "                 'Neut':['ein','jedes','kein','nicht jedes'],\n",
        "                 'next':2})\n",
        "\n",
        "#######################################################\n",
        "#2\n",
        "patterns_lutz_org.append({'type':'insertion',                # insert a predefined sequence \n",
        "                 'dependent':[''],              # property of the generated text it depends on\n",
        "                 'dependency': -1,                    # on which previous node it depends\n",
        "                 '':['ist'],        # use when the last node is Plural\n",
        "                 'next':3})                            \n",
        "\n",
        "#######################################################\n",
        "#3\n",
        "patterns_lutz_org.append({'type':'generate',\n",
        "                 'any': True,\n",
        "                 'num_samples':8,\n",
        "                 'pos':[['ADJ']],\n",
        "                 'next':4})\n",
        "\n",
        "#######################################################\n",
        "#4\n",
        "patterns_lutz_org.append({'type':'insertion',\n",
        "                 'text':['und','oder','so gilt','.','.','.','.','.'],\n",
        "                 'next':0})\n",
        "\n"
      ],
      "metadata": {
        "id": "r_1VKGOh-8jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patterns_lutz_var = []\n",
        "\n",
        "\n",
        "#######################################################\n",
        "#0\n",
        "patterns_lutz_var.append({'type':'generate',                 # use the language model to produce text\n",
        "                 'any': True,                         # word can be found anywhere in the text\n",
        "                 'num_samples':20,                    # number of samples that comply with the criteria\n",
        "                 'pos':[['NOUN']],     # should be either sequence adjective, noun or only noun\n",
        "                 'number': [['Sing']],\n",
        "                 'case':[['Nom']],         # the Noun should be nominative\n",
        "                 'next':1})                           # next node\n",
        "\n",
        "            \n",
        "#######################################################\n",
        "#1\n",
        "patterns_lutz_var.append({'type':'insertion',\n",
        "                 'dependent':['gender'],\n",
        "                 'dependency': -1,\n",
        "                 'position': 'before',                      # only possible with insertion\n",
        "                 'Fem':['eine','jede','keine','nicht jede'],  \n",
        "                 'Masc':['ein','jeder','kein','nicht jeder'],\n",
        "                 'Neut':['ein','jedes','kein','nicht jedes'],\n",
        "                 'next':2})\n",
        "\n",
        "#######################################################\n",
        "#2\n",
        "patterns_lutz_var.append({'type':'insertion',                # insert a predefined sequence \n",
        "                 'dependent':[''],              # property of the generated text it depends on\n",
        "                 'dependency': -1,                    # on which previous node it depends\n",
        "                 '':['ist'],        # use when the last node is Plural\n",
        "                 'next':3})                            \n",
        "\n",
        "#######################################################\n",
        "#3\n",
        "patterns_lutz_var.append({'type':'generate',\n",
        "                 'any': False,\n",
        "                 'num_samples':64,\n",
        "                 'pos':[['ADJ'],['DET','NOUN']],\n",
        "                 'case':[[''],['','Nom']],\n",
        "                 'words':[[],[['ein','eine'],[]]],\n",
        "                 'next':4})\n",
        "\n",
        "#######################################################\n",
        "#4\n",
        "patterns_lutz_var.append({'type':'insertion',\n",
        "                 'text':['und','oder','so gilt','.','.','.','.','.'],\n",
        "                 'next':0})\n",
        "\n"
      ],
      "metadata": {
        "id": "vOea6FflS4BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZIyH50tM3NZ"
      },
      "outputs": [],
      "source": [
        "patterns_1 = []\n",
        "\n",
        "#######################################################\n",
        "#0\n",
        "patterns_1.append({'type':'generate',                 # use the language model to produce text\n",
        "                 'any': True,                         # word can be found anywhere in the text\n",
        "                 'num_samples':20,                    # number of samples that comply with the criteria\n",
        "                 'pos':[['ADJ','NOUN'],['NOUN']],     # should be either sequence adjective, noun or only noun\n",
        "                 'case':[['','Nom'],['Nom']],         # the Noun should be nominative\n",
        "                 'add_det': [1,0],                    # add an article in front of the sequence\n",
        "                 'next':1})                           # next node\n",
        "\n",
        "#######################################################\n",
        "#1\n",
        "patterns_1.append({'type':'insertion',                # insert a predefined sequence \n",
        "                 'dependent':['number'],              # property of the generated text it depends on\n",
        "                 'dependency': -1,                    # on which previous node it depends\n",
        "                 'Plur':['sind','sind nicht'],        # use when the last node is Plural\n",
        "                 'Sing':['ist','ist nicht'],          # use when teh last node is Singular\n",
        "                 'next':2})                            \n",
        "\n",
        "#######################################################\n",
        "#2\n",
        "patterns_1.append({'type':'generate',\n",
        "                 'any': False,\n",
        "                 'num_samples':8,\n",
        "                 'pos':[['ADJ'],['DET','NOUN']],\n",
        "                 'case':[[''],['','Nom']],\n",
        "                 'words':[[],[['der','die','das'],[]]],\n",
        "                 'next':3})\n",
        "\n",
        "#######################################################\n",
        "#3\n",
        "patterns_1.append({'type':'insertion',\n",
        "                 'text':['denn'],\n",
        "                 'next':0})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a6qQOkeM3Na"
      },
      "outputs": [],
      "source": [
        "patterns_2 = []\n",
        "\n",
        "#######################################################\n",
        "#0\n",
        "patterns_2.append({'type':'insertion',\n",
        "                 'text':['ich','du','er','sie','es','wir'], #'ihr' is not corrected labeled by Spacy\n",
        "                 'next':1})\n",
        "\n",
        "#######################################################\n",
        "#1\n",
        "patterns_2.append({'type':'insertion',\n",
        "                 'dependent':['number','person'],\n",
        "                 'dependency': -1,\n",
        "                 'Plur 1':['dürfen', 'müssen', 'dürfen nicht', 'müssen nicht', 'können', 'können nicht'],\n",
        "                 'Plur 2':['dürft', 'müsst', 'dürft nicht', 'müsst nicht', 'könnt', 'könnt nicht'],\n",
        "                 'Plur 3':['dürfen', 'müssen', 'dürfen nicht', 'müssen nicht', 'können', 'können nicht'], \n",
        "                 'Sing 1':['darf','muss','darf nicht','muss nicht','kann','kann nicht'],\n",
        "                 'Sing 2':['darfst','musst','darfst nicht','musst nicht','kannst','kannst nicht'],\n",
        "                 'Sing 3':['darf','muss','darf nicht','muss nicht','kann','kann nicht'],  \n",
        "                 'next':2})\n",
        "\n",
        "#######################################################\n",
        "#2\n",
        "patterns_2.append({'type':'generate',\n",
        "                 'any': False,\n",
        "                 'num_samples':20,\n",
        "                 'pos':[['VERB'],['AUX','VERB']],\n",
        "                 'verbform':[['Inf'],['','Inf']],\n",
        "                 'next':3})\n",
        "\n",
        "#######################################################\n",
        "#3\n",
        "patterns_2.append({'type':'insertion',\n",
        "                 'text':['denn'],\n",
        "                 'next':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWi4HleGM3Nc"
      },
      "outputs": [],
      "source": [
        "patterns_3 = []\n",
        "\n",
        "#######################################################\n",
        "#0\n",
        "patterns_3.append({'type':'generate',\n",
        "                 'any': True,\n",
        "                 'num_samples':20,\n",
        "                 'pos':[['ADJ','NOUN'],['NOUN']],\n",
        "                 'case':[['','Nom'],['Nom']],\n",
        "                 'add_det': [1,0],\n",
        "                 'rand_next': [1,4]})               # list of next nodes to choose from randomly\n",
        "\n",
        "#######################################################\n",
        "#1\n",
        "patterns_3.append({'type':'insertion',\n",
        "                 'dependent':['number'],\n",
        "                 'dependency': -1,\n",
        "                 'Plur':['sind','sind nicht'],\n",
        "                 'Sing':['ist','ist nicht'],\n",
        "                 'rand_next': [2,5]})\n",
        "\n",
        "#######################################################\n",
        "#2\n",
        "patterns_3.append({'type':'generate',\n",
        "                 'any': False,\n",
        "                 'num_samples':8,\n",
        "                 'pos':[['ADJ'],['DET','NOUN']],\n",
        "                 'case':[[''],['','Nom']],\n",
        "                 'words':[[],[['der','die','das'],[]]],\n",
        "                 'next':3})\n",
        "\n",
        "#######################################################\n",
        "#3\n",
        "patterns_3.append({'type':'insertion',\n",
        "                 'text':['denn'],\n",
        "                 'next':0})\n",
        "\n",
        "#######################################################\n",
        "#4\n",
        "patterns_3.append({'type':'generate',\n",
        "                 'any': False,\n",
        "                 'num_samples': 100,\n",
        "                 'pos':[['VERB'],['AUX','VERB']],\n",
        "                 'verbform':[['Inf'],['','Inf']],\n",
        "                 'next':3,\n",
        "                 'if_failed':1})                       # where to continue if no option is found\n",
        "\n",
        "#######################################################\n",
        "#5\n",
        "patterns_3.append({'type':'generate',\n",
        "                 'any': False,\n",
        "                 'num_samples':90,\n",
        "                 'pos':[['ADJ'],['AUX']],\n",
        "                 'next':3,\n",
        "                 'if_failed':2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw5uHQn_M3Ne"
      },
      "outputs": [],
      "source": [
        "def check_pos(pos_tags, idx,doc):\n",
        "    pos = [item.pos_ for item in doc]\n",
        "    return pos == pos_tags[idx]\n",
        "\n",
        "def check_word(words, idx,doc):\n",
        "    comp_words = words[idx]\n",
        "    checked = False\n",
        "    for i, word in enumerate(comp_words):\n",
        "        if word == []:\n",
        "            checked = True\n",
        "        elif word == doc[i].text:\n",
        "            checked = True\n",
        "            \n",
        "    return checked\n",
        "\n",
        "def check_case(cases, idx,doc):\n",
        "    comp_cases = cases[idx]\n",
        "    checked = False\n",
        "    for i, case in enumerate(comp_cases):\n",
        "        if case == '':\n",
        "            checked = True\n",
        "        elif doc[i].morph.to_dict()['Case'] == case:\n",
        "            checked = True\n",
        "            \n",
        "    return checked\n",
        "\n",
        "def check_num(nums, idx,doc):\n",
        "    comp_nums = nums[idx]\n",
        "    checked = False\n",
        "    for i, nums in enumerate(comp_nums):\n",
        "        if nums == '':\n",
        "            checked = True\n",
        "        elif doc[i].morph.to_dict()['Number'] == nums:\n",
        "            checked = True\n",
        "            \n",
        "    return checked\n",
        "\n",
        "def check_verbform(verbforms, idx,doc):\n",
        "    forms = verbforms[idx]\n",
        "    checked = False\n",
        "    for i, form in enumerate(forms):\n",
        "        if form == '':\n",
        "            checked = True\n",
        "        elif 'VerbForm' in doc[i].morph.to_dict().keys():\n",
        "            if doc[i].morph.to_dict()['VerbForm'] == form:\n",
        "            \n",
        "                checked = True\n",
        "            \n",
        "    return checked\n",
        "\n",
        "def check_all(conditions,max_idx,doc):\n",
        "    \n",
        "    for idx in range(max_idx):\n",
        "        checked = True\n",
        "        for condition in conditions:\n",
        "            checked = checked and condition(idx,doc)\n",
        "        if checked: \n",
        "            return True\n",
        "        \n",
        "    return False\n",
        "        \n",
        "    \n",
        "def store_words(doc):\n",
        "    text = ' '.join([item.text for item in doc])\n",
        "    dct = {'text':' '.join([item.text for item in doc]),\n",
        "           'pos':[],'morph':[],'dep':[]}\n",
        "    \n",
        "    for word in doc:\n",
        "        dct['pos'].append(word.pos_)\n",
        "        dct['dep'].append(word.dep_)\n",
        "        dct['morph'].append(word.morph.to_dict())\n",
        "        \n",
        "    return dct\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWszgcEFM3Nf"
      },
      "outputs": [],
      "source": [
        "def get_pos_idx(pos_tags,n_gram):\n",
        "    idx_lst = []\n",
        "    for i, pos in enumerate(pos_tags):\n",
        "\n",
        "        if n_gram['pos'] == pos:\n",
        "            idx_lst.append(i)\n",
        "            \n",
        "    return idx_lst\n",
        "\n",
        "            \n",
        "def get_criteria_idx(criteria, n_gram):\n",
        "    poss_idx = np.asarray(criteria[0](n_gram))\n",
        "    if len(criteria) > 1: \n",
        "        for criterium in criteria[1:]: \n",
        "            poss_idx = np.settdif1d(poss_idx,criterium(n_gram))\n",
        "        \n",
        "    return poss_idx[0]\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWHxoZxkM3Nh"
      },
      "outputs": [],
      "source": [
        "def get_any(generated,check,lengths,min_return = 5):\n",
        "    found_words = []\n",
        "    for sent in generated:\n",
        "            doc = nlp(sent)\n",
        "            for length in lengths:            \n",
        "                for j in range(len(doc)-length):\n",
        "                    \n",
        "                    n_gram = doc[j:j+length]\n",
        "\n",
        "                    if check(n_gram):\n",
        "                        found_words.append(store_words(n_gram))\n",
        "                        \n",
        "                        if len(found_words) > min_return: \n",
        "                            return found_words\n",
        "                        \n",
        "    return found_words\n",
        "    \n",
        "def get_first(generated,check,lengths, min_return = 5):\n",
        "    found_words = []\n",
        "    for sent in generated:\n",
        "            doc = nlp(sent.strip())\n",
        "            for length in lengths:            \n",
        "                n_gram = doc[:length]\n",
        "                if check(n_gram):\n",
        "                    found_words.append(store_words(n_gram))\n",
        "                        \n",
        "                    if len(found_words) > min_return: \n",
        "                        return found_words\n",
        "                    \n",
        "    return found_words\n",
        "\n",
        "\n",
        "\n",
        "def process_generative_pattern(pattern, prompt):\n",
        "    anywhere = False\n",
        "    if 'any' in pattern.keys():\n",
        "        if pattern['any'] == True:\n",
        "            anywhere = True\n",
        "            \n",
        "    if 'num_samples' in pattern.keys():\n",
        "        num_samples = pattern['num_samples']\n",
        "    else:\n",
        "        num_samples = 5\n",
        "        \n",
        "    num_gpt_samples = 30\n",
        "    \n",
        "    if num_samples > num_gpt_samples:\n",
        "        num_gpt_samples = num_samples\n",
        "        \n",
        "    if anywhere: \n",
        "        generated = gpt2_generate(prompt,num_return_sequences=num_gpt_samples)\n",
        "    else: \n",
        "        generated = gpt2_generate(prompt,num_return_sequences=num_gpt_samples)\n",
        "\n",
        "    conditions = []\n",
        "    criteria = []\n",
        "    lengths = []\n",
        "    if 'pos' in pattern.keys():\n",
        "        max_idx = len(pattern['pos'])\n",
        "        conditions.append(functools.partial(check_pos,pattern['pos']))\n",
        "        criteria.append(functools.partial(get_pos_idx,pattern['pos']))\n",
        "        lengths += [len(item) for item in pattern['pos']]\n",
        "        \n",
        "    if 'words' in pattern.keys():\n",
        "        conditions.append(functools.partial(check_word,pattern['words']))\n",
        "\n",
        "    if 'number' in pattern.keys():\n",
        "        conditions.append(functools.partial(check_num,pattern['number']))\n",
        "        \n",
        "    if 'verbform' in pattern.keys():\n",
        "        conditions.append(functools.partial(check_verbform,pattern['verbform']))\n",
        "        \n",
        "   \n",
        "    lengths = list(set(lengths))\n",
        "    \n",
        "    check = functools.partial(check_all,conditions,max_idx)\n",
        "    get_idx = functools.partial(get_criteria_idx,criteria)\n",
        "    \n",
        "    \n",
        "        \n",
        "    if anywhere:\n",
        "        found_words = get_any(generated,check,lengths, min_return = num_samples)\n",
        "        \n",
        "    else:\n",
        "        found_words = get_first(generated,check,lengths, min_return = num_samples)\n",
        "        \n",
        "    if not found_words:\n",
        "        return '', 0\n",
        "    \n",
        "    word = random.choice(found_words)\n",
        "    return word, get_idx(word)\n",
        "    \n",
        "        \n",
        "                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qytTxj3mM3Ni"
      },
      "outputs": [],
      "source": [
        "article_dict = {'Fem':'die','Masc':'der','Neut':'das'}\n",
        "\n",
        "def generate_patterns(prompt,patterns,loops,stop_pattern,print_loops=False):\n",
        "    next_pattern = 0\n",
        "    found_lst = []\n",
        "    count = 0\n",
        "    while count < loops:\n",
        "        \n",
        "        pattern = patterns[next_pattern]\n",
        "        before = False\n",
        "        if 'position' in pattern.keys():\n",
        "          if pattern['position'] == 'before':\n",
        "            before = True\n",
        "\n",
        "            \n",
        "        if pattern['type'] == 'generate':\n",
        "            found_word, index = process_generative_pattern(pattern,prompt)\n",
        "            \n",
        "            if not found_word:\n",
        "                success = False\n",
        "                if not 'if_failed' in pattern.keys():\n",
        "                    print(prompt)\n",
        "                    print('''no completion found, please try again by pressing the play button\n",
        "                    of this cell''')\n",
        "\n",
        "                    return prompt\n",
        "            else:\n",
        "                success = True\n",
        "\n",
        "            if 'add_det' in pattern.keys() and success:\n",
        "                dependency = pattern['add_det'][index]\n",
        "                if pattern['add_det'][dependency] > - 1:\n",
        "\n",
        "                    gender = found_word['morph'][dependency]['Gender']\n",
        "                    number = found_word['morph'][dependency]['Number']\n",
        "\n",
        "                    if number == 'Plur':\n",
        "                        article = 'die'\n",
        "\n",
        "                    else: \n",
        "                        article = article_dict[gender]\n",
        "\n",
        "                    found_word['text'] = article + ' ' + found_word['text']\n",
        "        else:\n",
        "            success = True\n",
        "            if 'dependent' in pattern.keys():\n",
        "                query = ''\n",
        "                dependency = pattern['dependency']\n",
        "                if 'number' in pattern['dependent']:                \n",
        "                    query += found_lst[dependency]['morph'][-1]['Number']\n",
        "                if 'person' in pattern['dependent']:\n",
        "                    query += ' ' + str(found_lst[dependency]['morph'][-1]['Person'])\n",
        "\n",
        "                if 'gender' in pattern['dependent']:                \n",
        "                    query += found_lst[dependency]['morph'][-1]['Gender']\n",
        "\n",
        "\n",
        "                word = random.choice(pattern[query])\n",
        "\n",
        "            else: \n",
        "                word = random.choice(pattern['text'])\n",
        "\n",
        "            word_size = len(nlp(word))\n",
        "            doc = nlp(prompt + ' ' + word)[-word_size:]\n",
        "            found_word = store_words(doc)\n",
        "\n",
        "\n",
        "        if success: \n",
        "            if found_lst:                                 # not the first loop\n",
        "                if before:\n",
        "                  prompt_lst = prompt.split()\n",
        "                  prompt = ' '.join(prompt_lst[:-1] + [found_word['text'].strip()] + [prompt_lst[-1]])\n",
        "                  found_lst = [found_word] + found_lst\n",
        "                else: \n",
        "                  prompt += ' ' + found_word['text'].strip()\n",
        "                  found_lst.append(found_word)\n",
        "            else:\n",
        "                prompt = found_word['text'].strip()\n",
        "                found_lst.append(found_word)       \n",
        "\n",
        "            if 'rand_next' in pattern.keys():\n",
        "                next_pattern = random.choice(pattern['rand_next'])\n",
        "            else: \n",
        "                next_pattern = pattern['next']\n",
        "        else: \n",
        "            next_pattern = pattern['if_failed']\n",
        "            \n",
        "        if next_pattern == stop_pattern: \n",
        "            count +=1\n",
        "        if print_loops:\n",
        "          print(prompt)\n",
        "    return prompt\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRL0dts-M3Nm"
      },
      "outputs": [],
      "source": [
        "prompt = '<|endoftext|>.'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating the pattern"
      ],
      "metadata": {
        "id": "DvCKtsj2b4jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_patterns = 2\n",
        "print(generate_patterns(prompt, patterns_3,number_patterns,stop_pattern = 3,print_loops=True))"
      ],
      "metadata": {
        "id": "67OzVT_xb34J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The original scheme of Theo Lutz. \n",
        "Dependent on the corpus the model is trained on, the sequence of \"ist\" followed by an adjective is not too common. So you might need to run this cell a few times. Unfortunately the Kant model will almost always return \"absolute\" as adjective, if the model is required to follow the \"ist\". That is why the option \"any\" is set to True. So the results are a bit random."
      ],
      "metadata": {
        "id": "e9SC2EFPaKAb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "iAuhIsI5M3Nn",
        "outputId": "be366079-e3fd-4ad8-be09-d951662734a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grund\n",
            "nicht jeder Grund\n",
            "nicht jeder Grund ist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nicht jeder Grund ist ersten\n",
            "nicht jeder Grund ist ersten .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nicht jeder Grund ist ersten . Fassung\n",
            "nicht jeder Grund ist ersten . keine Fassung\n",
            "nicht jeder Grund ist ersten . keine Fassung ist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nicht jeder Grund ist ersten . keine Fassung ist letzte\n",
            "nicht jeder Grund ist ersten . keine Fassung ist letzte und\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nicht jeder Grund ist ersten . keine Fassung ist letzte und Z.\n",
            "nicht jeder Grund ist ersten . keine Fassung ist letzte und nicht jedes Z.\n",
            "nicht jeder Grund ist ersten . keine Fassung ist letzte und nicht jedes Z. ist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nicht jeder Grund ist ersten . keine Fassung ist letzte und nicht jedes Z. ist letzte\n",
            "nicht jeder Grund ist ersten . keine Fassung ist letzte und nicht jedes Z. ist letzte\n"
          ]
        }
      ],
      "source": [
        "number_patterns = 3\n",
        "print(generate_patterns(prompt, patterns_lutz_org,number_patterns,stop_pattern = 4,print_loops=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below the pattern is slightly modified, so that also \"ist ein/eine\" is allowed"
      ],
      "metadata": {
        "id": "KAno1Qklajfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_patterns = 2\n",
        "print(generate_patterns(prompt, patterns_lutz_var,number_patterns,stop_pattern = 4,print_loops=True))"
      ],
      "metadata": {
        "id": "HzV3F0asajGX",
        "outputId": "3a8ff222-0f81-480f-a2d7-537f3caa9e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-750975169e60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnumber_patterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatterns_lutz_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_patterns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_loops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-60-a7c39cd01f1b>\u001b[0m in \u001b[0;36mgenerate_patterns\u001b[0;34m(prompt, patterns, loops, stop_pattern, print_loops)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'generate'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mfound_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_generative_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound_word\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-20ef9f60cd5a>\u001b[0m in \u001b[0;36mprocess_generative_pattern\u001b[0;34m(pattern, prompt)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manywhere\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mfound_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-20ef9f60cd5a>\u001b[0m in \u001b[0;36mget_any\u001b[0;34m(generated, check, lengths, min_return)\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mn_gram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_gram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                         \u001b[0mfound_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_gram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0bfa2705d67b>\u001b[0m in \u001b[0;36mcheck_all\u001b[0;34m(conditions, max_idx, doc)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mchecked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcondition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconditions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mchecked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchecked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchecked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0bfa2705d67b>\u001b[0m in \u001b[0;36mcheck_num\u001b[0;34m(nums, idx, doc)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnums\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mchecked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Number'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mchecked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Number'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create multiple lines"
      ],
      "metadata": {
        "id": "BD4AaSPdNiLR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBwmFD8GM3No"
      },
      "outputs": [],
      "source": [
        "for k in range(10):\n",
        "    loop = random.choice([2,3])\n",
        "    loop = 2\n",
        "    print(generate_patterns(prompt,patterns_2,loop,stop_pattern = 3))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "llm_theo_lutz.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}